# -*- coding: utf-8 -*-
"""
drop_autonumber_daemon.py
åŸæœ‰åŠŸèƒ½: è‡ªåŠ¨ç¼–å· + Like-Saver æœ¬åœ°æœåŠ¡ + ç›‘å¬
æ–°å¢åŠŸèƒ½: æ¯æ¬¡ä¿å­˜/é‡å‘½åå›¾ç‰‡æ—¶è‡ªåŠ¨æ›´æ–° images.json ç´¢å¼•æ–‡ä»¶
"""

import os
import re
import csv
import time
import json
import threading
import traceback
from pathlib import Path
from typing import List, Tuple, Optional, Set
from http.server import ThreadingHTTPServer, BaseHTTPRequestHandler
from urllib.parse import urlparse
from urllib.request import Request, urlopen

# ============ åŸºç¡€é…ç½® ============
DEFAULT_BASE = r"C:\Users\Solarigin\Pictures\X"
IMAGE_EXTS = {".jpg", ".jpeg", ".png", ".bmp", ".gif", ".tiff", ".webp"}

FOLDER_NUM_WIDTH = 5  # æ–‡ä»¶å¤¹ç¼–å·ä½æ•° -> 00001_
FILE_NUM_WIDTH = 3  # å›¾ç‰‡ç¼–å·ä½æ•° -> _001
ASSIGN_MODE = "append"  # append(ç»­å°¾) / fill(è¡¥æ´)
FILE_SORT_MODE = "name"  # name / mtime / exifï¼ˆexif éœ€ Pillowï¼‰
CONFLICT_DIRS = "dedup"  # ç›®å½•å†²çªï¼šskip / dedup
CONFLICT_FILES = "skip"  # æ–‡ä»¶å†²çªï¼šskip / dedup

WATCH = True  # é»˜è®¤ç›‘å¬æ¨¡å¼
SCAN_INTERVAL = 2.0  # æ‰«æé—´éš”ç§’
STABILITY_CHECKS = 3  # ç¨³å®šæ€§æ£€æŸ¥æ¬¡æ•°
PREVIEW = False  # é¢„è§ˆï¼ˆä¸è½ç›˜ï¼‰

# é€šçŸ¥åç«¯ï¼šauto / winsdk / win10toast / burnttoast / none
DEFAULT_NOTIFY_BACKEND = "auto"

# Like-Saverï¼ˆæœ¬åœ° HTTPï¼‰é»˜è®¤å¼€å¯
LIKE_SAVER_ENABLED = True
LIKE_SAVER_PORT = 38999
LIKE_SAVER_UA = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0 Safari/537.36"
XL_MARKER = ".xlikes"  # ä»…ä½œæ ‡è¯†ï¼Œä¸æ‹¦æˆªæ”¹å

LOG_DIR = Path(__file__).with_name("logs")
LOG_DIR.mkdir(exist_ok=True)
LOG_FILE = LOG_DIR / "drop_autonumber.log"
REPORT_CSV = ""  # å¯è®¾ä¸ºè·¯å¾„å†™æ˜ å°„æŠ¥å‘Š

# éšè—/ç³»ç»Ÿç›®å½•è¿‡æ»¤ï¼ˆä»…ä¸€çº§å­ç›®å½•ï¼‰
IGNORE_HIDDEN_PREFIX = True
IGNORE_SYSNAMES = {"system volume information", "$recycle.bin"}

# æ­£åˆ™
RE_NUMBERED = re.compile(r'^(?P<num>\d{5})_(?P<base>.+)$')
RE_STRIP_PREFIX = re.compile(r'^(?:\d{5}_)+')


# ============ æ—¥å¿— ============
def log(msg: str):
    ts = time.strftime("%Y-%m-%d %H:%M:%S")
    line = f"[{ts}] {msg}"
    try:
        with open(LOG_FILE, "a", encoding="utf-8") as f:
            f.write(line + "\n")
    except Exception:
        pass
    print(line)


# ============ é€šçŸ¥ï¼ˆå¯é€‰åç«¯ï¼‰ ============
class Notifier:
    def __init__(self, prefer: str = "auto"):
        self.backend = None
        self._n = None
        self._xml = None
        self.toaster = None

        prefer = (prefer or "auto").lower()

        def try_winsdk():
            try:
                from winsdk.windows.ui import notifications as _n  # type: ignore
                from winsdk.windows.data import xml as _xml  # type: ignore
                self._n = _n
                self._xml = _xml
                self.app_id = "DropAutoNumber.Python.App"
                self.backend = "winsdk"
                return True
            except Exception:
                return False

        def try_win10toast():
            try:
                from win10toast import ToastNotifier  # type: ignore
                self.toaster = ToastNotifier()
                self.backend = "win10toast"
                return True
            except Exception:
                return False

        if prefer == "winsdk":
            ok = try_winsdk() or try_win10toast() or True
            if not ok: self.backend = "burnttoast"
        elif prefer == "win10toast":
            ok = try_win10toast() or try_winsdk() or True
            if not ok: self.backend = "burnttoast"
        elif prefer == "burnttoast":
            self.backend = "burnttoast"
        elif prefer == "none":
            self.backend = "none"
        else:
            # auto: winsdk -> win10toast -> burnttoast
            if not try_winsdk():
                if not try_win10toast():
                    self.backend = "burnttoast"

        log(f"Notifier backend = {self.backend} (prefer={prefer})")

    def notify(self, title: str, message: str, duration: int = 5):
        if self.backend == "none":
            return
        log(f"NOTIFY: {title} | {message}")
        try:
            if self.backend == "winsdk" and self._n and self._xml:
                doc = self._xml.dom.XmlDocument()
                doc.load_xml(
                    f"<toast><visual><binding template='ToastGeneric'>"
                    f"<text>{title}</text><text>{message}</text>"
                    f"</binding></visual></toast>"
                )
                self._n.ToastNotificationManager.create_toast_notifier(self.app_id) \
                    .show(self._n.ToastNotification(doc))
                return

            if self.backend == "win10toast" and self.toaster:
                self.toaster.show_toast(title, message, duration=duration, threaded=False)
                return

            if self.backend == "burnttoast":
                import shutil, subprocess
                if shutil.which("powershell"):
                    safe_title = str(title).replace("'", "''")
                    safe_msg = str(message).replace("'", "''")
                    ps = (
                        "if (Get-Module -ListAvailable -Name BurntToast) "
                        f"{{ New-BurntToastNotification -Text '{safe_title}', '{safe_msg}' }}"
                    )
                    subprocess.Popen(
                        ["powershell", "-NoProfile", "-Command", ps],
                        stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL
                    )
                return

        except Exception as e:
            log(f"notify error: {e}")


notifier: Notifier  # set in main()


# ============ åŸºç¡€å·¥å…· ============
def list_subfolders_once(base: Path) -> List[Path]:
    res = []
    sysnames = {s.lower() for s in IGNORE_SYSNAMES}
    with os.scandir(base) as it:
        for e in it:
            if e.is_dir():
                name = e.name
                if IGNORE_HIDDEN_PREFIX and name.startswith("."):
                    continue
                if name.lower() in sysnames:
                    continue
                res.append(Path(e.path))
    return res


def list_loose_images(base: Path) -> List[Path]:
    files = []
    with os.scandir(base) as it:
        for e in it:
            if e.is_file():
                p = Path(e.path)
                if p.suffix.lower() in IMAGE_EXTS:
                    files.append(p)
    return files


def strip_chain_prefix(name: str) -> str:
    return RE_STRIP_PREFIX.sub("", name)


def ensure_unique_temp(path: Path, suffix: str) -> Path:
    tmp = path.with_name(path.name + suffix)
    i = 1
    while tmp.exists():
        tmp = path.with_name(path.name + f"{suffix}{i}")
        i += 1
    return tmp


def dedup_target(target: Path) -> Path:
    if not target.exists():
        return target
    i = 1
    stem, suf = target.stem, target.suffix
    alt = target.with_name(f"{stem}_{i}{suf}")
    while alt.exists():
        i += 1
        alt = target.with_name(f"{stem}_{i}{suf}")
    return alt


def file_size(path: Path) -> int:
    try:
        return path.stat().st_size
    except FileNotFoundError:
        return -1


def wait_stable(paths: List[Path], interval: float, checks: int) -> None:
    if checks <= 0:
        return
    for _ in range(checks):
        sizes1 = [file_size(p) for p in paths]
        time.sleep(interval)
        sizes2 = [file_size(p) for p in paths]
        if sizes1 != sizes2:
            time.sleep(interval)
            return wait_stable(paths, interval, checks)
    return


# ============ EXIFï¼ˆå¯é€‰ï¼‰ ============
def get_exif_ts(p: Path) -> Optional[float]:
    try:
        from PIL import Image, ExifTags  # type: ignore
        key = {v: k for k, v in ExifTags.TAGS.items()}
        with Image.open(p) as im:
            ex = im.getexif()
            if not ex:
                return None
            from datetime import datetime
            for name in ("DateTimeOriginal", "DateTimeDigitized", "DateTime"):
                tag = key.get(name)
                if tag is None:
                    continue
                val = ex.get(tag)
                if isinstance(val, str):
                    try:
                        return datetime.strptime(val, "%Y:%m:%d %H:%M:%S").timestamp()
                    except Exception:
                        pass
    except Exception:
        return None
    return None


def sort_images(files: List[Path], mode: str) -> List[Path]:
    if mode == "mtime":
        return sorted(files, key=lambda p: (p.stat().st_mtime, p.name.lower()))
    if mode == "exif":
        def key(p: Path):
            ts = get_exif_ts(p)
            if ts is not None:
                return (0, ts, p.name.lower())
            return (1, p.stat().st_mtime, p.name.lower())

        return sorted(files, key=key)
    return sorted(files, key=lambda p: p.name.lower())


# ============ æ–°å¢ï¼šè‡ªåŠ¨æ›´æ–° images.json ============
def update_gallery_index():
    """
    æ‰«æ DEFAULT_BASEï¼ˆä½ çš„å›¾åº“æ ¹ï¼‰å¹¶å†™å…¥ images.jsonã€‚
    æ¯ä¸ªæ¡ç›®ï¼š{path, folder, name, mtime}ï¼Œpath ä¸ºç›¸å¯¹è·¯å¾„ï¼ˆ/ åˆ†éš”ï¼‰ã€‚
    """
    try:
        base = Path(DEFAULT_BASE)
        items = []
        for p in sorted(base.rglob("*")):
            if p.is_file() and p.suffix.lower() in IMAGE_EXTS:
                try:
                    m = int(p.stat().st_mtime)
                except Exception:
                    m = 0
                rel = p.relative_to(base).as_posix()
                folder = rel.split('/')[-2] if '/' in rel else ''
                items.append({'path': rel, 'folder': folder, 'name': p.name, 'mtime': m})
        out = base / "images.json"
        with open(out, "w", encoding="utf-8") as f:
            json.dump(items, f, ensure_ascii=False, indent=2)
        log(f"[Gallery] images.json å·²æ›´æ–°ï¼ˆ{len(items)} æ¡ï¼‰ -> {out}")
    except Exception as e:
        log(f"[Gallery] æ›´æ–° images.json å¤±è´¥: {e}")


# ============ ç¼–å·ç­–ç•¥ ============
def collect_existing_numbers(base: Path) -> Tuple[Set[int], List[Tuple[Path, int, str]], List[Path]]:
    used: Set[int] = set()
    numbered = []
    unnumbered = []
    for f in list_subfolders_once(base):
        m = RE_NUMBERED.match(f.name)
        if m:
            n = int(m.group("num"))
            b = m.group("base")
            numbered.append((f, n, b))
            used.add(n)
        else:
            unnumbered.append(f)
    return used, numbered, unnumbered


def next_number_append(used: Set[int]) -> int:
    return (max(used) + 1) if used else 1


def next_number_fill(used: Set[int]) -> int:
    n = 1
    while n in used:
        n += 1
    return n


def assign_number(used: Set[int], mode: str) -> int:
    if mode == "fill":
        n = next_number_fill(used)
    else:
        n = next_number_append(used)
    used.add(n)
    return n


# ============ å›¾ç‰‡æ‰¹é‡é‡å‘½å/ç»Ÿä¸€å‘½å ============
def normalize_xlikes_folder(folder: Path, file_num_width: int, sort_mode: str, conflict_policy: str) -> int:
    """
    ä»…æŠŠä¸ç¬¦åˆâ€œ{folder.name}_NNN.extâ€æ¨¡å¼çš„æ–‡ä»¶æ”¹åä¸ºä¸‹ä¸€ä¸ªè¿ç»­ç¼–å·ï¼›
    å·²ç¬¦åˆè§„èŒƒçš„ä¿ç•™åŸç¼–å·ã€‚è¿”å›è°ƒæ•´æ•°é‡ã€‚
    """
    imgs = [p for p in folder.iterdir() if p.is_file() and p.suffix.lower() in IMAGE_EXTS]
    if not imgs:
        return 0

    pat = re.compile(rf'^{re.escape(folder.name)}_(\d{{{file_num_width}}})$', re.IGNORECASE)

    conforming: List[Tuple[Path, int]] = []
    nonconforming: List[Path] = []
    for p in imgs:
        m = pat.fullmatch(p.stem)
        if m:
            try:
                conforming.append((p, int(m.group(1))))
            except Exception:
                nonconforming.append(p)
        else:
            nonconforming.append(p)

    if not nonconforming:
        return 0

    max_idx = max([idx for _, idx in conforming], default=0)
    nonconforming = sort_images(nonconforming, sort_mode)

    changed = 0
    for src in nonconforming:
        while True:
            max_idx += 1
            dst = folder / f"{folder.name}_{max_idx:0{file_num_width}d}{src.suffix.lower()}"
            if not dst.exists():
                break
        try:
            os.rename(src, dst)
            log(f"[XLikesç»Ÿä¸€å‘½å] {src.name} -> {dst.name}")
            changed += 1
        except Exception as e:
            log(f"[XLikesç»Ÿä¸€å‘½å] æ”¹åå¤±è´¥ï¼š{src.name} -> {e}")

    if changed:
        notifier.notify("Xç‚¹èµå‘½åå·²ç»Ÿä¸€", f"{folder.name}ï¼šè°ƒæ•´ {changed} ä¸ª")
        # é preview æ¨¡å¼ä¸‹æ›´æ–° images.json
        try:
            update_gallery_index()
        except Exception as e:
            log(f"[Gallery] æ›´æ–° images.json å¤±è´¥: {e}")
    return changed


def current_max_index(folder: Path, file_num_width: int) -> int:
    """æ‰«æ {folder.name}_NNN.* çš„æœ€å¤§ NNNã€‚"""
    pat = re.compile(rf'^{re.escape(folder.name)}_(\d{{{file_num_width}}})$', re.IGNORECASE)
    max_idx = 0
    for p in folder.iterdir():
        if p.is_file() and p.suffix.lower() in IMAGE_EXTS:
            m = pat.fullmatch(p.stem)
            if m:
                try:
                    idx = int(m.group(1))
                    if idx > max_idx:
                        max_idx = idx
                except Exception:
                    pass
    return max_idx


def rename_images_in_folder(folder: Path, preview: bool, file_num_width: int,
                            conflict_policy: str, sort_mode: str,
                            report_rows: List[Tuple[str, str, str]]) -> None:
    # é˜²å‘†ï¼šå®½åº¦å¿…é¡»æ˜¯ int
    try:
        file_num_width = int(file_num_width)
    except Exception:
        log(f"âš ï¸ file_num_width éæ•°å­—ï¼š{file_num_width}ï¼Œå·²å›é€€ä¸ºé»˜è®¤ {FILE_NUM_WIDTH}")
        file_num_width = FILE_NUM_WIDTH

    imgs = [p for p in folder.iterdir() if p.is_file() and p.suffix.lower() in IMAGE_EXTS]
    if not imgs:
        return
    imgs = sort_images(imgs, sort_mode)

    plan = []
    for i, src in enumerate(imgs, 1):
        dst_name = f"{folder.name}_{i:0{file_num_width}d}{src.suffix.lower()}"
        dst = folder / dst_name
        if src == dst:
            continue
        plan.append((src, dst))
    if not plan:
        log(f"ğŸ“ [{folder.name}] å›¾ç‰‡é˜¶æ®µï¼šæ— éœ€ä¿®æ”¹")
        return

    log(f"=== å›¾ç‰‡é˜¶æ®µ [{folder.name}]ï¼š{len(plan)} ä¸ªéœ€æ”¹å ===")
    for s, d in plan:
        log(f"{s.name}  ->  {d.name}")

    if preview:
        log("ğŸ” é¢„è§ˆæ¨¡å¼ï¼šæœªå¯¹å›¾ç‰‡åšæ”¹åŠ¨\n")
        notifier.notify("å›¾ç‰‡é¢„è§ˆå®Œæˆ", f"{folder.name} å°†é‡å‘½å {len(plan)} ä¸ªæ–‡ä»¶")
        return

    temps = []
    for s, _ in plan:
        tmp = ensure_unique_temp(s, ".__renametmp__")
        log(f"[æ”¹å] {s.name}  ->  {tmp.name}")
        os.rename(s, tmp)
        temps.append(tmp)
    for tmp, (_, final_dst) in zip(temps, plan):
        target = final_dst
        if target.exists():
            if conflict_policy == "skip":
                base_original = tmp.with_name(tmp.name.split(".__renametmp__")[0])
                back = base_original
                k = 1
                while back.exists():
                    back = base_original.with_name(base_original.stem + f"_keep{k}" + base_original.suffix)
                    k += 1
                os.rename(tmp, back)
                log(f"[è·³è¿‡] ç›®æ ‡å­˜åœ¨ï¼š{target.name} -> å›é€€ {back.name}")
                continue
            else:
                target = dedup_target(target)
        os.rename(tmp, target)
        log(f"[å·²æ”¹å] {tmp.name} -> {target.name}")
    notifier.notify("å›¾ç‰‡é‡å‘½åå®Œæˆ", f"{folder.name} å…±å¤„ç† {len(plan)} ä¸ªæ–‡ä»¶")

    # æ›´æ–° images.jsonï¼ˆè‹¥éé¢„è§ˆï¼‰
    try:
        if not preview:
            update_gallery_index()
    except Exception as e:
        log(f"[Gallery] æ›´æ–° images.json å¤±è´¥: {e}")


# ============ å¤„ç†å…¥å£å¯¹è±¡ ============
def handle_unumbered_folder(base: Path, folder: Path, used: Set[int],
                            mode: str, preview: bool, dir_conflict: str,
                            file_conflict: str, file_num_width: int,
                            sort_mode: str, report_rows: List[Tuple[str, str, str]]) -> None:
    base_name = strip_chain_prefix(folder.name) or folder.name
    n = assign_number(used, mode)
    final_name = f"{n:0{FOLDER_NUM_WIDTH}d}_{base_name}"
    final_path = base / final_name

    if RE_NUMBERED.match(folder.name):
        log(f"â„¹ï¸ å·²ç¼–å·ç›®å½•è·³è¿‡ï¼š{folder.name}")
        return

    if folder == final_path:
        log(f"â„¹ï¸ ç›®å½•å·²æ˜¯ç›®æ ‡åï¼š{folder.name}")
    else:
        log(f"=== ç›®å½•é˜¶æ®µï¼š{folder.name} -> {final_name}")
        if preview:
            log("ğŸ” é¢„è§ˆæ¨¡å¼ï¼šæœªå¯¹ç›®å½•åšæ”¹åŠ¨\n")
            notifier.notify("ç›®å½•é¢„è§ˆå®Œæˆ", f"{folder.name} -> {final_name}")
        else:
            tmp = ensure_unique_temp(folder, ".__renametmp__")
            os.rename(folder, tmp)
            target = final_path
            if target.exists():
                if dir_conflict == "skip":
                    log(f"[è·³è¿‡] ç›®æ ‡å·²å­˜åœ¨ï¼š{target.name}ï¼ˆç›®å½•é˜¶æ®µï¼‰")
                    notifier.notify("ç›®å½•é‡å‘½åè·³è¿‡", f"{final_name} å·²å­˜åœ¨")
                    return
                else:
                    target = dedup_target(target)
            os.rename(tmp, target)
            folder = target
            notifier.notify("ç›®å½•é‡å‘½åå®Œæˆ", f"{folder.name}")

    rename_images_in_folder(folder, preview, file_num_width, file_conflict, sort_mode, report_rows)

    # rename_images_in_folder å†…å·²ä¼šæ›´æ–° images.jsonï¼ˆé previewï¼‰ï¼Œè¿™é‡Œä¸å¿…é‡å¤è°ƒç”¨


def handle_loose_image(base: Path, img: Path, used: Set[int], mode: str,
                       preview: bool, dir_conflict: str, file_conflict: str,
                       file_num_width: int, sort_mode: str,
                       report_rows: List[Tuple[str, str, str]]) -> None:
    base_name = strip_chain_prefix(img.stem) or img.stem
    n = assign_number(used, mode)
    folder_name = f"{n:0{FOLDER_NUM_WIDTH}d}_{base_name}"
    folder_path = base / folder_name

    log(f"=== æ‰“åŒ…å•å›¾ï¼š{img.name} -> {folder_name}\\")
    if preview:
        notifier.notify("å•å›¾é¢„è§ˆå®Œæˆ", f"{img.name} å°†æ‰“åŒ…è‡³ {folder_name}")
        return

    target_folder = folder_path
    if target_folder.exists():
        if dir_conflict == "skip":
            log(f"[è·³è¿‡] ç›®æ ‡æ–‡ä»¶å¤¹å·²å­˜åœ¨ï¼š{target_folder.name}")
            notifier.notify("æ‰“åŒ…è·³è¿‡", f"{target_folder.name} å·²å­˜åœ¨")
            return
        else:
            target_folder = dedup_target(target_folder)
    target_folder.mkdir(parents=True, exist_ok=True)

    dst_single = target_folder / img.name
    if dst_single.exists():
        if file_conflict == "skip":
            log(f"[è·³è¿‡] ç›®æ ‡å†…å·²å­˜åœ¨åŒåæ–‡ä»¶ï¼š{dst_single.name}")
        else:
            dst_single = dedup_target(dst_single)
            log(f"[å»é‡] è°ƒæ•´ç›®æ ‡æ–‡ä»¶åï¼š{dst_single.name}")
    os.rename(img, dst_single)

    # âœ… ä¿®å¤ç‚¹ï¼šè¿™é‡Œå‚æ•°å¿…é¡»æ˜¯ (folder, preview, file_num_width, conflict_policy, sort_mode, report_rows)
    rename_images_in_folder(target_folder, preview, file_num_width, file_conflict, sort_mode, report_rows)

    notifier.notify("å•å›¾æ‰“åŒ…å®Œæˆ", f"{folder_name}")

    # rename_images_in_folder å·²è´Ÿè´£æ›´æ–° images.jsonï¼ˆè‹¥é previewï¼‰


# ============ æ‰¹å¤„ç† & ç›‘å¬ ============
def process_once(base: Path, assign_mode: str, preview: bool, file_sort: str,
                 conflict_dirs: str, conflict_files: str,
                 report_csv: str) -> None:
    if not base.exists():
        notifier.notify("è·¯å¾„ä¸å­˜åœ¨", str(base))
        log(f"âŒ è·¯å¾„ä¸å­˜åœ¨ï¼š{base}")
        return

    report_rows: List[Tuple[str, str, str]] = []
    try:
        pending = list_loose_images(base)
        wait_stable(pending, interval=SCAN_INTERVAL, checks=STABILITY_CHECKS)

        used, numbered, unnumbered = collect_existing_numbers(base)

        # å…ˆæ•£å›¾
        for img in list_loose_images(base):
            handle_loose_image(base, img, used, assign_mode, preview,
                               conflict_dirs, conflict_files, FILE_NUM_WIDTH, file_sort, report_rows)

        # å†æœªç¼–å·ç›®å½•
        unnumbered_sorted = sorted(unnumbered, key=lambda p: strip_chain_prefix(p.name).lower())
        for folder in unnumbered_sorted:
            handle_unumbered_folder(base, folder, used, assign_mode, preview,
                                    conflict_dirs, conflict_files, FILE_NUM_WIDTH, file_sort, report_rows)

        if report_csv:
            try:
                with open(report_csv, "w", newline="", encoding="utf-8-sig") as f:
                    w = csv.writer(f)
                    w.writerow(["TYPE", "FROM", "TO"])
                    w.writerows(report_rows)
                log(f"ğŸ“ æŠ¥å‘Šå·²å†™å…¥ï¼š{report_csv}ï¼ˆ{len(report_rows)} æ¡ï¼‰")
            except Exception as e:
                log(f"âš ï¸ æŠ¥å‘Šå†™å…¥å¤±è´¥ï¼š{e}")

        notifier.notify("æ‰¹å¤„ç†å®Œæˆ", f"{base}")
        log("ğŸ‰ å®Œæˆï¼ˆé¢„è§ˆï¼‰" if preview else "ğŸ‰ å®Œæˆï¼ˆå·²è½ç›˜ï¼‰")

        # æœ€åä¸€æ¬¡æ€§æ›´æ–° images.jsonï¼ˆè‹¥é previewï¼‰
        try:
            if not preview:
                update_gallery_index()
        except Exception as e:
            log(f"[Gallery] æ›´æ–° images.json å¤±è´¥: {e}")

    except Exception:
        err = traceback.format_exc()
        notifier.notify("è¿è¡Œé”™è¯¯", "è¯·æŸ¥çœ‹æ—¥å¿—")
        log(err)


def watch_loop(base: Path, assign_mode: str, preview: bool, file_sort: str,
               conflict_dirs: str, conflict_files: str, report_csv: str) -> None:
    if not base.exists():
        notifier.notify("è·¯å¾„ä¸å­˜åœ¨", str(base))
        log(f"âŒ è·¯å¾„ä¸å­˜åœ¨ï¼š{base}")
        return

    notifier.notify("å¼€å§‹ç›‘å¬", f"{base}")
    log(f"ğŸ‘€ ç›‘å¬ä¸­ï¼š{base}")

    seen_dirs = set(p.name for p in list_subfolders_once(base))
    seen_imgs = set(p.name for p in list_loose_images(base))
    used, _, _ = collect_existing_numbers(base)

    report_rows: List[Tuple[str, str, str]] = []

    try:
        while True:
            time.sleep(SCAN_INTERVAL)
            curr_dirs = set(p.name for p in list_subfolders_once(base))
            curr_imgs = set(p.name for p in list_loose_images(base))
            new_dirs = [base / n for n in (curr_dirs - seen_dirs)]
            new_imgs = [base / n for n in (curr_imgs - seen_imgs)]

            if not new_dirs and not new_imgs:
                seen_dirs, seen_imgs = curr_dirs, curr_imgs
                continue

            wait_stable(new_dirs + new_imgs, interval=SCAN_INTERVAL, checks=STABILITY_CHECKS)

            # æ–°æ•£å›¾
            for img in [p for p in new_imgs if p.suffix.lower() in IMAGE_EXTS]:
                handle_loose_image(base, img, used, assign_mode, preview,
                                   conflict_dirs, conflict_files, FILE_NUM_WIDTH, file_sort, report_rows)

            # æ–°ç›®å½•ï¼ˆä»…æœªç¼–å·ï¼‰
            for d in new_dirs:
                if RE_NUMBERED.match(d.name):
                    log(f"â„¹ï¸ æ–°å¢ç›®å½•å·²ç¼–å·ï¼Œä¿æŒï¼š{d.name}")
                    continue
                handle_unumbered_folder(base, d, used, assign_mode, preview,
                                        conflict_dirs, conflict_files, FILE_NUM_WIDTH, file_sort, report_rows)

            seen_dirs = set(p.name for p in list_subfolders_once(base))
            seen_imgs = set(p.name for p in list_loose_images(base))

            if report_csv:
                try:
                    with open(report_csv, "w", newline="", encoding="utf-8-sig") as f:
                        w = csv.writer(f)
                        w.writerow(["TYPE", "FROM", "TO"])
                        w.writerows(report_rows)
                except Exception as e:
                    log(f"âš ï¸ æŠ¥å‘Šå†™å…¥å¤±è´¥ï¼š{e}")
    except KeyboardInterrupt:
        notifier.notify("å·²åœæ­¢ç›‘å¬", f"{base}")
        log("ğŸ›‘ ç›‘å¬å·²åœæ­¢")


# ============ Like-Saverï¼ˆåˆå…¥ç‰ˆï¼‰ ============
SAFE_NAME_RE = re.compile(r"[^A-Za-z0-9._-]")


def safe_name(s: str) -> str:
    return SAFE_NAME_RE.sub("_", s or "")


def ext_from_url(u: str) -> str:
    parsed = urlparse(u)
    q = {}
    if parsed.query:
        for kv in parsed.query.split("&"):
            if "=" in kv:
                k, v = kv.split("=", 1)
                q[k] = v
    fmt = q.get("format")
    if fmt:
        return "." + fmt.lower()
    path = parsed.path
    if "." in path:
        return "." + path.rsplit(".", 1)[-1].lower()
    return ".jpg"


def download(url: str, to_file: Path, timeout=30):
    to_file.parent.mkdir(parents=True, exist_ok=True)
    req = Request(url, headers={"User-Agent": LIKE_SAVER_UA})
    with urlopen(req, timeout=timeout) as resp, open(to_file, "wb") as f:
        f.write(resp.read())


def resolve_author_folder(base: Path, author: str) -> Path:
    """
    è‹¥å·²å­˜åœ¨å½¢å¦‚ 00001_author çš„ç¼–å·ç›®å½•ï¼Œåˆ™è¿”å›å®ƒï¼›
    å¦åˆ™ä½¿ç”¨ base/authorï¼ˆæ–°å»ºï¼‰ï¼Œç­‰å¾…å¤–å±‚ watcher ä¹‹åè‡ªåŠ¨ç¼–å·ã€‚
    åŒæ—¶æ”¾ç½® XL_MARKER æ ‡è®°ã€‚
    """
    clean = safe_name(author)
    candidates = list_subfolders_once(base)
    for p in candidates:
        if strip_chain_prefix(p.name).lower() == clean.lower():
            (p / XL_MARKER).touch(exist_ok=True)
            return p
    new_dir = base / clean
    new_dir.mkdir(parents=True, exist_ok=True)
    (new_dir / XL_MARKER).touch(exist_ok=True)
    return new_dir


class LikeSaverHandler(BaseHTTPRequestHandler):
    # é™é»˜æ—¥å¿—
    def log_message(self, fmt, *args):
        return

    def do_POST(self):
        if self.path != "/save":
            self.send_error(404);
            return
        try:
            n = int(self.headers.get("Content-Length", "0") or "0")
            data = self.rfile.read(n)
            payload = json.loads(data.decode("utf-8", "ignore"))
            author = safe_name(payload.get("author"))
            tweet_id = safe_name(str(payload.get("tweetId")))
            images = [str(u) for u in (payload.get("images") or []) if str(u).startswith("http")]
            if not author or not tweet_id or not images:
                self.send_error(400, "invalid payload");
                return

            dest_dir = resolve_author_folder(LIKE_BASE_DIR, author)

            # ç›´æ¥æŒ‰â€œç›®å½•å_é€’å¢ç¼–å·â€å‘½åä¿å­˜
            idx = current_max_index(dest_dir, FILE_NUM_WIDTH)
            saved = 0
            for url in images:
                ext = ext_from_url(url)
                while True:
                    idx += 1
                    dst = dest_dir / f"{dest_dir.name}_{idx:0{FILE_NUM_WIDTH}d}{ext}"
                    if not dst.exists():
                        break
                try:
                    download(url, dst)
                    saved += 1
                    log(f"[LikeSaver] ä¿å­˜ -> {dst.name}")
                except Exception as e:
                    log(f"[LikeSaver] ä¸‹è½½å¤±è´¥ï¼š{url} -> {e}")

            # å…œåº•æ ‡å‡†åŒ–ï¼ˆå†å²é—ç•™ï¼‰
            changed = normalize_xlikes_folder(dest_dir, FILE_NUM_WIDTH, FILE_SORT_MODE, CONFLICT_FILES)

            notifier.notify("å·²ä¿å­˜ç‚¹èµå›¾ç‰‡", f"{author} / {tweet_id}ï¼š{saved} æˆåŠŸï¼›è§„èŒƒåŒ– {changed} ä¸ª")
            log(f"[LikeSaver] {author}/{tweet_id} -> saved={saved}, normalized={changed}")

            # æ›´æ–° images.jsonï¼ˆå·²ä¿å­˜/ä¿®æ”¹å›¾ç‰‡æ—¶ï¼‰
            try:
                update_gallery_index()
            except Exception as e:
                log(f"[Gallery] æ›´æ–° images.json å¤±è´¥: {e}")

            self.send_response(200)
            self.send_header("Content-Type", "application/json; charset=utf-8")
            self.end_headers()
            self.wfile.write(json.dumps({"ok": True, "saved": saved}).encode("utf-8"))

        except Exception as e:
            notifier.notify("ç‚¹èµä¿å­˜å‡ºé”™", str(e))
            log(f"[LikeSaver] error: {e}")
            self.send_response(500)
            self.send_header("Content-Type", "application/json; charset=utf-8")
            self.end_headers()
            self.wfile.write(json.dumps({"ok": False, "error": str(e)}).encode("utf-8"))


def start_like_saver(port: int, base: Path):
    global LIKE_BASE_DIR
    LIKE_BASE_DIR = base
    srv = ThreadingHTTPServer(("127.0.0.1", port), LikeSaverHandler)
    t = threading.Thread(target=srv.serve_forever, name="LikeSaver", daemon=True)
    t.start()
    log(f"[LikeSaver] ç›‘å¬ http://127.0.0.1:{port}/save â†’ {base}")
    notifier.notify("ç‚¹èµä¿å­˜å™¨å·²å¯åŠ¨", f"127.0.0.1:{port}")


# ============ CLI ============
def build_parser() -> 'argparse.ArgumentParser':
    import argparse
    p = argparse.ArgumentParser(description="æŠ•æ”¾å³ç¼–å· + ç‚¹èµä¿å­˜ï¼ˆåå°å¸¸é©» + Windows é€šçŸ¥ï¼‰")
    p.add_argument("--base", type=str, default=DEFAULT_BASE, help="ç›®æ ‡è·¯å¾„")
    p.add_argument("--watch", action="store_true", default=WATCH, help="æŒç»­ç›‘å¬æ¨¡å¼ï¼ˆé»˜è®¤å¼€ï¼‰")
    p.add_argument("--once", action="store_true", help="åªå¤„ç†å½“å‰å¾…åŠåé€€å‡º")
    p.add_argument("--preview", action="store_true", default=PREVIEW, help="é¢„è§ˆæ¨¡å¼ï¼ˆä¸è½ç›˜ï¼‰")
    p.add_argument("--no-preview", dest="preview", action="store_false", help="å…³é—­é¢„è§ˆï¼Œæ‰§è¡Œæ”¹å/ç§»åŠ¨")

    p.add_argument("--assign", type=str, default=ASSIGN_MODE, choices=["append", "fill"], help="ç¼–å·ç­–ç•¥")
    p.add_argument("--file-sort", type=str, default=FILE_SORT_MODE, choices=["name", "mtime", "exif"], help="å›¾ç‰‡æ’åº")
    p.add_argument("--conflict-dirs", type=str, default=CONFLICT_DIRS, choices=["skip", "dedup"], help="ç›®å½•å†²çªç­–ç•¥")
    p.add_argument("--conflict-files", type=str, default=CONFLICT_FILES, choices=["skip", "dedup"], help="æ–‡ä»¶å†²çªç­–ç•¥")
    p.add_argument("--interval", type=float, default=SCAN_INTERVAL, help="ç›‘å¬æ‰«æé—´éš”ç§’")
    p.add_argument("--stability", type=int, default=STABILITY_CHECKS, help="ç¨³å®šæ€§æ£€æŸ¥æ¬¡æ•°")
    p.add_argument("--report-csv", type=str, default=REPORT_CSV, help="æ˜ å°„æŠ¥å‘Š CSVï¼ˆç•™ç©º=ä¸ç”Ÿæˆï¼‰")

    # é€šçŸ¥
    p.add_argument("--notify-backend", type=str, default=DEFAULT_NOTIFY_BACKEND,
                   choices=["auto", "winsdk", "win10toast", "burnttoast", "none"],
                   help="é€šçŸ¥åç«¯é€‰æ‹©ï¼ˆé»˜è®¤ autoï¼‰")
    p.add_argument("--notify-test", action="store_true", help="å¯åŠ¨æ—¶ç«‹å³å¼¹ä¸€æ¡æµ‹è¯•é€šçŸ¥")

    # Like-Saver
    p.add_argument("--like-saver", action="store_true", default=LIKE_SAVER_ENABLED, help="å¯ç”¨ç‚¹èµä¿å­˜å™¨ï¼ˆé»˜è®¤å¼€ï¼‰")
    p.add_argument("--no-like-saver", dest="like_saver", action="store_false", help="ç¦ç”¨ç‚¹èµä¿å­˜å™¨")
    p.add_argument("--like-port", type=int, default=LIKE_SAVER_PORT, help="ç‚¹èµä¿å­˜å™¨ç«¯å£ï¼ˆé»˜è®¤ 38999ï¼‰")

    return p


def main():
    args = build_parser().parse_args()
    base = Path(args.base)

    global notifier
    notifier = Notifier(prefer=args.notify_backend)

    if args.notify_test:
        notifier.notify("è„šæœ¬å·²å¯åŠ¨", f"ç›‘å¬ï¼š{base}")
        time.sleep(0.2)

    # è¦†ç›–é—´éš”å’Œç¨³å®šæ€§å‚æ•°
    global SCAN_INTERVAL, STABILITY_CHECKS
    SCAN_INTERVAL = args.interval
    STABILITY_CHECKS = args.stability

    # å¯åŠ¨ Like-Saverï¼ˆå…ˆäº watch_loopï¼‰
    if args.like_saver:
        start_like_saver(args.like_port, base)

    if args.once:
        process_once(base, args.assign, args.preview, args.file_sort,
                     args.conflict_dirs, args.conflict_files, args.report_csv)
    else:
        watch_loop(base, args.assign, args.preview, args.file_sort,
                   args.conflict_dirs, args.conflict_files, args.report_csv)


if __name__ == "__main__":
    main()
